#!/bin/bash
#
#SBATCH --job-name="ChemTab UQ Distributed"
#SBATCH --output=ChemTab_UQ_Distributed.out
#SBATCH --mail-user=dwyerdei@buffalo.edu
#SBATCH --mail-type=end
#SBATCH --cluster=ub-hpc
#SBATCH --partition=general-compute
#SBATCH --qos=general-compute
#SBATCH --threads-per-core=1    # do not use hyperthreads (i.e. CPUs = physical cores below)
#SBATCH --cpus-per-task=5       # number of CPUs per process (we want extra for data loaders)
#SBATCH --ntasks-per-node=2     # This needs to match Trainer(devices=...), Also: it seems that GPU nodes have only 2 GPUs per node anyways...
#SBATCH --gpus-per-node=2       # We need to request it "per-node" because pytorch needs visibility of all node's GPUs for some reason...
#SBATCH --mem=50G
## #SBATCH --signal=SIGUSR1@90
#SBATCH --nodes=8 # This needs to match Trainer(nodes=...)
#SBATCH --time=01:00:00

# --nodes cannot be set dynamically!! (in sheebang)
# but it can be detected dynammically using srun magic!
num_nodes=$(srun hostname | sort | uniq -c | wc -l)
# logic is: prints all hostnames, then sorts, then groups & counts group sizes, then counts number of groups

# this version is deprecated...
#num_nodes=$((num_nodes/2)) # WARNING: this will fail if you use more than 2 tasks per node!
echo num nodes: $num_nodes

# let the user know if their EXTRA_PL_ARGS went through or not
[ -z "$EXTRA_PL_ARGS" ] && echo EXTRA_PL_ARGS is empty!! >&2

diagnostic_CLI_args="--logger True --profiler simple --device-stats-monitor --detect_anomaly" # use these only for "debug mode"
#diagnostic_CLI_args='--fast_dev_run 1000'
#diagnostic_CLI_args=
EXTRA_PL_ARGS1="$EXTRA_PL_ARGS $diagnostic_CLI_args" # NOTE: this should be an environment variable given by the user when submitting sbatch!!
lightning_CLI_args="$EXTRA_PL_ARGS1 --num_nodes=$num_nodes --devices=2 --accelerator=gpu --strategy=ddp --gradient_clip_algorithm=value --gradient_clip_val 0.2"

echo diagnostic_CLI_args: $diagnostic_CLI_args
echo EXTRA_PL_ARGS: $EXTRA_PL_ARGS
echo lightning_CLI_args: $lightning_CLI_args

#Let's start some work
source /user/dwyerdei/.bash_profile
conda activate pytorch_distributed_cuda3
# NOTE: this command is for slurmi sessions!
#srun --ntasks-per-node=2 python ChemtabUQ.py --num_nodes=$num_nodes --devices=2 --accelerator=gpu --strategy=ddp --gradient_clip_algorithm=value --gradient_clip_val 0.5
srun --ntasks-per-node=2 python ChemtabUQ.py $lightning_CLI_args #--num_nodes=$num_nodes --devices=2 --accelerator=gpu --strategy=ddp --gradient_clip_algorithm=value --gradient_clip_val 0.5
# NOTE: gradient_clip_value=0.5 recommended by PL docs
#Let's finish some work
